{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c39c31f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "from config_loader import load_config\n",
    "from mlflow_setup import setup_mlflow\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import CoherenceModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30dbe38e",
   "metadata": {},
   "source": [
    "–û–±—â–∏–µ —Ñ—É–Ω–∫—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41a4ac5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_topics(model, vectorizer, n_words=10):\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "    topics = []\n",
    "    for topic in model.components_:\n",
    "        top_words_idx = topic.argsort()[:-n_words-1:-1]\n",
    "        topics.append([feature_names[i] for i in top_words_idx])\n",
    "    return topics\n",
    "\n",
    "def calculate_coherence(topics, texts):\n",
    "    tokenized_texts = [str(text).split() for text in texts]\n",
    "    coherence_model = CoherenceModel(\n",
    "        topics=topics,\n",
    "        texts=tokenized_texts,\n",
    "        dictionary=Dictionary(tokenized_texts),\n",
    "        coherence='c_v'\n",
    "    )\n",
    "    return coherence_model.get_coherence()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2dfa4d",
   "metadata": {},
   "source": [
    "LDA 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "84f90695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞—é –∫–æ–Ω—Ñ–∏–≥ –∏–∑: ../config/lda_1.yaml\n",
      "‚úì Tracking URI: http://127.0.0.1:8080\n",
      "‚úì Experiment: topic_modeling\n",
      "‚úì –ì–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n",
      "–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ ../data/data_processed2.csv\n",
      "iteration: 1 of max_iter: 50\n",
      "iteration: 2 of max_iter: 50\n",
      "iteration: 3 of max_iter: 50\n",
      "iteration: 4 of max_iter: 50\n",
      "iteration: 5 of max_iter: 50, perplexity: 11.9279\n",
      "iteration: 6 of max_iter: 50\n",
      "iteration: 7 of max_iter: 50\n",
      "iteration: 8 of max_iter: 50\n",
      "iteration: 9 of max_iter: 50\n",
      "iteration: 10 of max_iter: 50, perplexity: 11.5192\n",
      "iteration: 11 of max_iter: 50\n",
      "iteration: 12 of max_iter: 50\n",
      "iteration: 13 of max_iter: 50\n",
      "iteration: 14 of max_iter: 50\n",
      "iteration: 15 of max_iter: 50, perplexity: 11.3988\n",
      "iteration: 16 of max_iter: 50\n",
      "iteration: 17 of max_iter: 50\n",
      "iteration: 18 of max_iter: 50\n",
      "iteration: 19 of max_iter: 50\n",
      "iteration: 20 of max_iter: 50, perplexity: 11.3897\n",
      "LDA –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: 7 —Ç–µ–º\n",
      "–ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: 0.5987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 03:59:51 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/25 03:59:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 11.39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 03:59:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/25 03:59:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–¢–µ–º—ã –º–æ–¥–µ–ª–∏:\n",
      "–¢–µ–º–∞ 1: —É–ª–∏—Ü–∞, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –∞–≤—Ç–æ–±—É—Å, –º–∞—Ä—à—Ä—É—Ç, –±—ã—Ç—å, –ø—É—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, —Ü–µ–Ω—Ç—Ä, –¥–≤–∏–∂–µ–Ω–∏–µ, –ª–∏–Ω–∏—è\n",
      "–¢–µ–º–∞ 2: –¥–≤–∏–∂–µ–Ω–∏–µ, —Ü–µ–Ω—Ç—Ä, —É–ª–∏—Ü–∞, –±—ã—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, –ø—É—Ç—å, –ø–æ–µ–∑–¥–∫–∞, –º–∞—Ä—à—Ä—É—Ç, –∞–≤—Ç–æ–±—É—Å, –ª–∏–Ω–∏—è\n",
      "–¢–µ–º–∞ 3: –ø–æ–µ–∑–¥–∫–∞, –ø—É—Ç—å, –±—ã—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, —Ü–µ–Ω—Ç—Ä, –º–∞—Ä—à—Ä—É—Ç, —É–ª–∏—Ü–∞, –∞–≤—Ç–æ–±—É—Å, –ø–æ–µ–∑–¥\n",
      "–¢–µ–º–∞ 4: –ø–æ–¥—Å–ª—É—à–∞—Ç—å, –ø—É—Ç—å, –ø–æ–µ–∑–¥, –∞–≤—Ç–æ–±—É—Å, –ª–∏–Ω–∏—è, –¥–≤–∏–∂–µ–Ω–∏–µ, –±—ã—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –º–∞—Ä—à—Ä—É—Ç\n",
      "–¢–µ–º–∞ 5: –º–∞—Ä—à—Ä—É—Ç, –±—ã—Ç—å, –∞–≤—Ç–æ–±—É—Å, —Ä–∞–±–æ—Ç–∞—Ç—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –ø—É—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, —É–ª–∏—Ü–∞, —Ü–µ–Ω—Ç—Ä, –ª–∏–Ω–∏—è\n",
      "–¢–µ–º–∞ 6: –ø–æ–µ–∑–¥, –¥–≤–∏–∂–µ–Ω–∏–µ, –ø—É—Ç—å, –±—ã—Ç—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –º–∞—Ä—à—Ä—É—Ç, –ª–∏–Ω–∏—è, –ø–æ–µ–∑–¥–∫–∞, —Ä–∞–±–æ—Ç–∞—Ç—å, –∞–≤—Ç–æ–±—É—Å\n",
      "–¢–µ–º–∞ 7: –ª–∏–Ω–∏—è, —Ä–∞–±–æ—Ç–∞—Ç—å, –ø—É—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, –ø–æ–µ–∑–¥, –±—ã—Ç—å, –º–∞—Ä—à—Ä—É—Ç, —Ü–µ–Ω—Ç—Ä, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –∞–≤—Ç–æ–±—É—Å\n",
      "LDA –º–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow. Run ID: bd00ff727c6141c388f53a20c4c158a5\n",
      "üèÉ View run lda_topic_model at: http://127.0.0.1:8080/#/experiments/4/runs/bd00ff727c6141c388f53a20c4c158a5\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é LDA\n",
    "cfg = load_config(\"lda_1\")\n",
    "\n",
    "# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "setup_mlflow(cfg)  \n",
    "\n",
    "with mlflow.start_run(run_name=\"lda_topic_model\") as run:\n",
    "    \n",
    "    # 1. –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_params({\n",
    "        \"vectorizer_max_features\": cfg['vectorizer']['max_features'],\n",
    "        \"vectorizer_ngram_range\": str(cfg['vectorizer']['ngram_range']),\n",
    "        \"vectorizer_max_df\": cfg['vectorizer']['max_df'],\n",
    "        \"vectorizer_min_df\": cfg['vectorizer']['min_df'],\n",
    "        \"lda_n_components\": cfg['lda']['n_components'],\n",
    "        \"lda_max_iter\": cfg['lda']['max_iter'],\n",
    "        \"lda_learning_method\": cfg['lda']['learning_method'],\n",
    "        \"lda_random_state\": cfg['lda']['random_state'],\n",
    "    \n",
    "    # evaluation —Ç–æ–∂–µ –Ω–∞ –∫–æ—Ä–Ω–µ–≤–æ–º —É—Ä–æ–≤–Ω–µ\n",
    "    \"evaluation_top_words\": cfg['evaluation']['top_words_count']\n",
    "    })\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {cfg['data']['input']['path']}\")\n",
    "    df_processed = pd.read_csv(\n",
    "        cfg['data']['input']['path'],\n",
    "        sep=cfg['data']['input']['delimiter'],\n",
    "        encoding=cfg['data']['input']['encoding']\n",
    "    )\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä–∞\n",
    "    count_vectorizer = CountVectorizer(\n",
    "        max_features = cfg['vectorizer']['max_features'],\n",
    "        ngram_range = tuple(cfg['vectorizer']['ngram_range']),\n",
    "        max_df = cfg['vectorizer']['max_df'],\n",
    "        min_df = cfg['vectorizer']['min_df'],\n",
    "    )\n",
    "    \n",
    "    texts = df_processed['message_clean_no_stopwords'].fillna('')\n",
    "    dataset = count_vectorizer.fit_transform(texts)\n",
    "    \n",
    "    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏ –æ–±—É—á–µ–Ω–∏–µ LDA\n",
    "    lda = LDA( \n",
    "        n_components=cfg['lda']['n_components'],\n",
    "        max_iter=cfg['lda']['max_iter'],    \n",
    "        learning_method=cfg['lda']['learning_method'],\n",
    "        evaluate_every=cfg['lda']['evaluate_every'],\n",
    "        random_state=cfg['lda']['random_state'],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    lda.fit(dataset)\n",
    "    print(f\"LDA –º–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞: {cfg['lda']['n_components']} —Ç–µ–º\")\n",
    "    \n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—ã \n",
    "    topics = extract_topics(lda, count_vectorizer, cfg['evaluation']['top_words_count'])\n",
    "    \n",
    "    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    coherence = calculate_coherence(topics, texts.tolist())\n",
    "    \n",
    "    metrics = {\n",
    "        \"perplexity\": lda.perplexity(dataset),\n",
    "        \"log_likelihood\": lda.score(dataset),\n",
    "        \"coherence\": coherence\n",
    "    }\n",
    "    \n",
    "    mlflow.log_metrics(metrics)\n",
    "    print(f\"–ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å –º–æ–¥–µ–ª–∏: {coherence:.4f}\")\n",
    "    print(f\"Perplexity: {lda.perplexity(dataset):.2f}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏\n",
    "    mlflow.sklearn.log_model(count_vectorizer, \"count_vectorizer\")\n",
    "    mlflow.sklearn.log_model(lda, \"lda_model1\")\n",
    "    \n",
    "    # –í—ã–≤–æ–¥–∏–º –∏ –ª–æ–≥–∏—Ä—É–µ–º —Ç–µ–º—ã\n",
    "    print(\"\\n–¢–µ–º—ã –º–æ–¥–µ–ª–∏:\")\n",
    "    for idx, topic_words in enumerate(topics, 1):\n",
    "        print(f\"–¢–µ–º–∞ {idx}: {', '.join(topic_words)}\")\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º —Ç–µ–º—ã –∫–∞–∫ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç\n",
    "    topics_content = \"\\n\".join(\n",
    "        [f\"–¢–µ–º–∞ {idx}: {', '.join(words)}\" for idx, words in enumerate(topics, 1)]\n",
    "    )\n",
    "    mlflow.log_text(topics_content, \"topics.txt\")\n",
    "    \n",
    "    print(f\"LDA –º–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow. Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53c3326f",
   "metadata": {},
   "source": [
    "LDA 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f2d8cf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞—é –∫–æ–Ω—Ñ–∏–≥ –∏–∑: ../config/lda_2.yaml\n",
      "‚úì Tracking URI: http://127.0.0.1:8080\n",
      "‚úì Experiment: topic_modeling\n",
      "‚úì –ì–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbd01167a9b840f1ab744e4cb82865df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccf4fd3907e146538693db0677423f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a900adf822c748f99e7b953cffe5b9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 100\n",
      "iteration: 2 of max_iter: 100\n",
      "iteration: 3 of max_iter: 100\n",
      "iteration: 4 of max_iter: 100\n",
      "iteration: 5 of max_iter: 100, perplexity: 14.2321\n",
      "iteration: 6 of max_iter: 100\n",
      "iteration: 7 of max_iter: 100\n",
      "iteration: 8 of max_iter: 100\n",
      "iteration: 9 of max_iter: 100\n",
      "iteration: 10 of max_iter: 100, perplexity: 14.0795\n",
      "iteration: 11 of max_iter: 100\n",
      "iteration: 12 of max_iter: 100\n",
      "iteration: 13 of max_iter: 100\n",
      "iteration: 14 of max_iter: 100\n",
      "iteration: 15 of max_iter: 100, perplexity: 14.1199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 04:25:58 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/25 04:25:59 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "–¢–µ–º—ã:\n",
      "–¢–µ–º–∞ 1: –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –º–∞—Ä—à—Ä—É—Ç, –±—ã—Ç—å, —É–ª–∏—Ü–∞, –∞–≤—Ç–æ–±—É—Å, –ø—É—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, –ª–∏–Ω–∏—è, —Ü–µ–Ω—Ç—Ä\n",
      "–¢–µ–º–∞ 2: –¥–≤–∏–∂–µ–Ω–∏–µ, —É–ª–∏—Ü–∞, –±—ã—Ç—å, —Ü–µ–Ω—Ç—Ä, –º–∞—Ä—à—Ä—É—Ç, –ø–æ–µ–∑–¥–∫–∞, –ø—É—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, –∞–≤—Ç–æ–±—É—Å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
      "–¢–µ–º–∞ 3: –ø–æ–µ–∑–¥–∫–∞, –±—ã—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, —Ü–µ–Ω—Ç—Ä, –º–∞—Ä—à—Ä—É—Ç, –ø—É—Ç—å, –ø–æ–µ–∑–¥, —É–ª–∏—Ü–∞, —Ä–∞–±–æ—Ç–∞—Ç—å, –ª–∏–Ω–∏—è\n",
      "–¢–µ–º–∞ 4: –¥–≤–∏–∂–µ–Ω–∏–µ, –±—ã—Ç—å, –ø—É—Ç—å, –ø–æ–µ–∑–¥–∫–∞, –º–∞—Ä—à—Ä—É—Ç, –ø–æ–µ–∑–¥, —Ü–µ–Ω—Ç—Ä, –ª–∏–Ω–∏—è, –∞–≤—Ç–æ–±—É—Å, —Ä–∞–±–æ—Ç–∞—Ç—å\n",
      "–¢–µ–º–∞ 5: –∞–≤—Ç–æ–±—É—Å, –±—ã—Ç—å, —É–ª–∏—Ü–∞, –º–∞—Ä—à—Ä—É—Ç, —Ä–∞–±–æ—Ç–∞—Ç—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –¥–≤–∏–∂–µ–Ω–∏–µ, –ø—É—Ç—å, –ª–∏–Ω–∏—è, —Ü–µ–Ω—Ç—Ä\n",
      "–¢–µ–º–∞ 6: –ø—É—Ç—å, –ø–æ–µ–∑–¥, –¥–≤–∏–∂–µ–Ω–∏–µ, –±—ã—Ç—å, –ø–æ–µ–∑–¥–∫–∞, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –º–∞—Ä—à—Ä—É—Ç, –ª–∏–Ω–∏—è, –∞–≤—Ç–æ–±—É—Å, —É–ª–∏—Ü–∞\n",
      "–¢–µ–º–∞ 7: –ª–∏–Ω–∏—è, –±—ã—Ç—å, –º–∞—Ä—à—Ä—É—Ç, –¥–≤–∏–∂–µ–Ω–∏–µ, –ø—É—Ç—å, –∞–≤—Ç–æ–±—É—Å, –ø–æ–µ–∑–¥, –ø–æ–µ–∑–¥–∫–∞, —Ä–∞–±–æ—Ç–∞—Ç—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
      "–¢–µ–º–∞ 8: –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –∞–≤—Ç–æ–±—É—Å, —É–ª–∏—Ü–∞, —Ä–∞–±–æ—Ç–∞—Ç—å, –±—ã—Ç—å, –º–∞—Ä—à—Ä—É—Ç, —Ü–µ–Ω—Ç—Ä, –¥–≤–∏–∂–µ–Ω–∏–µ, –ø—É—Ç—å, –ø–æ–µ–∑–¥\n",
      "–¢–µ–º–∞ 9: –ø–æ–µ–∑–¥, –ª–∏–Ω–∏—è, –±—ã—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, –º–∞—Ä—à—Ä—É—Ç, —Ä–∞–±–æ—Ç–∞—Ç—å, –ø–æ–µ–∑–¥–∫–∞, –ø–æ–¥—Å–ª—É—à–∞—Ç—å, –ø—É—Ç—å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
      "–¢–µ–º–∞ 10: —Ü–µ–Ω—Ç—Ä, –¥–≤–∏–∂–µ–Ω–∏–µ, –±—ã—Ç—å, –ø–æ–µ–∑–¥–∫–∞, —É–ª–∏—Ü–∞, –º–∞—Ä—à—Ä—É—Ç, –ø—É—Ç—å, —Ä–∞–±–æ—Ç–∞—Ç—å, –∞–≤—Ç–æ–±—É—Å, –ª–∏–Ω–∏—è\n",
      "–¢–µ–º–∞ 11: –º–∞—Ä—à—Ä—É—Ç, –±—ã—Ç—å, –∞–≤—Ç–æ–±—É—Å, —Ä–∞–±–æ—Ç–∞—Ç—å, –ø—É—Ç—å, —É–ª–∏—Ü–∞, –¥–≤–∏–∂–µ–Ω–∏–µ, –ª–∏–Ω–∏—è, –ø–æ–µ–∑–¥–∫–∞, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞\n",
      "–¢–µ–º–∞ 12: —É–ª–∏—Ü–∞, –º–∞—Ä—à—Ä—É—Ç, –±—ã—Ç—å, –ø—É—Ç—å, –∞–≤—Ç–æ–±—É—Å, —Ä–∞–±–æ—Ç–∞—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, —Ü–µ–Ω—Ç—Ä, –ª–∏–Ω–∏—è\n",
      "–¢–µ–º–∞ 13: –ø–æ–¥—Å–ª—É—à–∞—Ç—å, –ø–æ–µ–∑–¥, –ª–∏–Ω–∏—è, –±—ã—Ç—å, –ø—É—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, –∞–≤—Ç–æ–±—É—Å, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –º–∞—Ä—à—Ä—É—Ç, —Ä–∞–±–æ—Ç–∞—Ç—å\n",
      "–¢–µ–º–∞ 14: –ø–æ–µ–∑–¥, –±—ã—Ç—å, –¥–≤–∏–∂–µ–Ω–∏–µ, –ø–æ–µ–∑–¥–∫–∞, –æ—Å—Ç–∞–Ω–æ–≤–∫–∞, –º–∞—Ä—à—Ä—É—Ç, –ø—É—Ç—å, –ª–∏–Ω–∏—è, –ø–æ–¥—Å–ª—É—à–∞—Ç—å, –∞–≤—Ç–æ–±—É—Å\n",
      "–¢–µ–º–∞ 15: —Ä–∞–±–æ—Ç–∞—Ç—å, –ø—É—Ç—å, –±—ã—Ç—å, –∞–≤—Ç–æ–±—É—Å, –¥–≤–∏–∂–µ–Ω–∏–µ, –º–∞—Ä—à—Ä—É—Ç, —É–ª–∏—Ü–∞, –ª–∏–Ω–∏—è, —Ü–µ–Ω—Ç—Ä, –ø–æ–µ–∑–¥–∫–∞\n",
      "LDA –º–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow. Run ID: 9de1f32f9488427586e653ca74bd31e3\n",
      "üèÉ View run lda_15topics at: http://127.0.0.1:8080/#/experiments/4/runs/9de1f32f9488427586e653ca74bd31e3\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥\n",
    "cfg = load_config(\"lda_2\")\n",
    "\n",
    "# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç\n",
    "setup_mlflow(cfg)  \n",
    "\n",
    "with mlflow.start_run(run_name=f\"lda_{cfg['lda']['n_components']}topics\") as run:\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∞—Ä—Ç–µ—Ñ–∞–∫—Ç—ã –∏–∑ MLflow\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä\n",
    "    vectorizer_path = client.download_artifacts(\n",
    "        cfg['data']['vectorizer']['run_id'], \n",
    "        \"count_vectorizer\"\n",
    "    )\n",
    "    vectorizer = mlflow.sklearn.load_model(vectorizer_path)\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    data_path = client.download_artifacts(\n",
    "        cfg['data']['data']['run_id'], \n",
    "        \"data/data_processed2/data_processed2.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_params({\n",
    "        \"n_topics\": cfg['lda']['n_components'],\n",
    "        \"vectorizer_source\": cfg['data']['vectorizer']['run_id'],\n",
    "        \"data_source\": cfg['data']['data']['run_id'],\n",
    "        \"max_iter\": cfg['lda']['max_iter']\n",
    "    })\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    texts = df['message_clean_no_stopwords'].fillna('')\n",
    "    dataset = vectorizer.transform(texts)\n",
    "    \n",
    "    # –û–±—É—á–∞–µ–º LDA\n",
    "    lda = LDA(\n",
    "        n_components=cfg['lda']['n_components'],\n",
    "        max_iter=cfg['lda']['max_iter'],    \n",
    "        learning_method=cfg['lda']['learning_method'],\n",
    "        evaluate_every=cfg['lda']['evaluate_every'],\n",
    "        random_state=cfg['lda']['random_state'],\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    lda.fit(dataset)\n",
    "\n",
    "    topics = extract_topics(lda, vectorizer, n_words=10)\n",
    "    \n",
    "    # –°—á–∏—Ç–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏\n",
    "    coherence = calculate_coherence(topics, texts.tolist())\n",
    "    \n",
    "    mlflow.log_metrics({\n",
    "        \"perplexity\": lda.perplexity(dataset),\n",
    "        \"log_likelihood\": lda.score(dataset),\n",
    "        \"coherence\": coherence\n",
    "    })\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å\n",
    "    mlflow.sklearn.log_model(lda, \"lda_model2\")\n",
    "    \n",
    "    # –í—ã–≤–æ–¥–∏–º —Ç–µ–º—ã\n",
    "    print(\"\\n–¢–µ–º—ã:\")\n",
    "    for i, topic_words in enumerate(topics, 1):\n",
    "        print(f\"–¢–µ–º–∞ {i}: {', '.join(topic_words)}\")\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–µ–º—ã\n",
    "    with open(\"topics.txt\", \"w\") as f:\n",
    "        for i, words in enumerate(topics, 1):\n",
    "            f.write(f\"–¢–µ–º–∞ {i}: {', '.join(words)}\\n\")\n",
    "    mlflow.log_artifact(\"topics.txt\")\n",
    "    \n",
    "    print(f\"LDA –º–æ–¥–µ–ª—å –∑–∞–ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∞ –≤ MLflow. Run ID: {run.info.run_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509d23b",
   "metadata": {},
   "source": [
    "LDA 3 (–Ω–æ–≤—ã–π –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä + –Ω–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a7f5b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∂–∞—é –∫–æ–Ω—Ñ–∏–≥ –∏–∑: ../config/lda_3.yaml\n",
      "‚úì Tracking URI: http://127.0.0.1:8080\n",
      "‚úì Experiment: topic_modeling\n",
      "‚úì –ì–æ—Ç–æ–≤–æ –∫ –∑–∞–ø—É—Å–∫—É –Ω–æ–≤–æ–≥–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∞\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abb59830b36449eb6a6fb1d3af1dad3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 100\n",
      "iteration: 2 of max_iter: 100\n",
      "iteration: 3 of max_iter: 100\n",
      "iteration: 4 of max_iter: 100\n",
      "iteration: 5 of max_iter: 100, perplexity: 424.9296\n",
      "iteration: 6 of max_iter: 100\n",
      "iteration: 7 of max_iter: 100\n",
      "iteration: 8 of max_iter: 100\n",
      "iteration: 9 of max_iter: 100\n",
      "iteration: 10 of max_iter: 100, perplexity: 396.5783\n",
      "iteration: 11 of max_iter: 100\n",
      "iteration: 12 of max_iter: 100\n",
      "iteration: 13 of max_iter: 100\n",
      "iteration: 14 of max_iter: 100\n",
      "iteration: 15 of max_iter: 100, perplexity: 392.7948\n",
      "iteration: 16 of max_iter: 100\n",
      "iteration: 17 of max_iter: 100\n",
      "iteration: 18 of max_iter: 100\n",
      "iteration: 19 of max_iter: 100\n",
      "iteration: 20 of max_iter: 100, perplexity: 392.1191\n",
      "iteration: 21 of max_iter: 100\n",
      "iteration: 22 of max_iter: 100\n",
      "iteration: 23 of max_iter: 100\n",
      "iteration: 24 of max_iter: 100\n",
      "iteration: 25 of max_iter: 100, perplexity: 391.8181\n",
      "iteration: 26 of max_iter: 100\n",
      "iteration: 27 of max_iter: 100\n",
      "iteration: 28 of max_iter: 100\n",
      "iteration: 29 of max_iter: 100\n",
      "iteration: 30 of max_iter: 100, perplexity: 391.5792\n",
      "iteration: 31 of max_iter: 100\n",
      "iteration: 32 of max_iter: 100\n",
      "iteration: 33 of max_iter: 100\n",
      "iteration: 34 of max_iter: 100\n",
      "iteration: 35 of max_iter: 100, perplexity: 390.3348\n",
      "iteration: 36 of max_iter: 100\n",
      "iteration: 37 of max_iter: 100\n",
      "iteration: 38 of max_iter: 100\n",
      "iteration: 39 of max_iter: 100\n",
      "iteration: 40 of max_iter: 100, perplexity: 387.6839\n",
      "iteration: 41 of max_iter: 100\n",
      "iteration: 42 of max_iter: 100\n",
      "iteration: 43 of max_iter: 100\n",
      "iteration: 44 of max_iter: 100\n",
      "iteration: 45 of max_iter: 100, perplexity: 387.2131\n",
      "iteration: 46 of max_iter: 100\n",
      "iteration: 47 of max_iter: 100\n",
      "iteration: 48 of max_iter: 100\n",
      "iteration: 49 of max_iter: 100\n",
      "iteration: 50 of max_iter: 100, perplexity: 387.1444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/12/25 04:30:55 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/25 04:30:55 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "2025/12/25 04:31:01 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
      "2025/12/25 04:31:01 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–¢–µ–º—ã: 15\n",
      "Perplexity: 387.14\n",
      "Coherence: 0.4703\n",
      "Run ID: 9c87e1b8b13446ac9d420d611f900312\n",
      "üèÉ View run lda_15topics_new at: http://127.0.0.1:8080/#/experiments/4/runs/9c87e1b8b13446ac9d420d611f900312\n",
      "üß™ View experiment at: http://127.0.0.1:8080/#/experiments/4\n"
     ]
    }
   ],
   "source": [
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ–Ω—Ñ–∏–≥\n",
    "cfg = load_config(\"lda_3\")\n",
    "setup_mlflow(cfg)  \n",
    "\n",
    "with mlflow.start_run(run_name=f\"lda_{cfg['lda']['n_components']}topics_new\") as run:\n",
    "    \n",
    "    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ\n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    data_path = client.download_artifacts(\n",
    "        cfg['data']['data_run_id'], \n",
    "        \"output_data/data_without_stopwords.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(data_path)\n",
    "    \n",
    "    # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ç–æ—Ä\n",
    "    vectorizer = CountVectorizer(\n",
    "        max_features=cfg['vectorizer']['max_features'], \n",
    "        ngram_range=tuple(cfg['vectorizer']['ngram_range']),\n",
    "        max_df=cfg['vectorizer']['max_df'], \n",
    "        min_df=cfg['vectorizer']['min_df']\n",
    "    )\n",
    "    \n",
    "    # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "    texts = df['message_clean_no_stopwords'].fillna('')\n",
    "    dataset = vectorizer.fit_transform(texts)\n",
    "    texts_list = texts.tolist()\n",
    "    \n",
    "    # –õ–æ–≥–∏—Ä—É–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã\n",
    "    mlflow.log_params({\n",
    "        \"n_topics\": cfg['lda']['n_components'],\n",
    "        \"data_source\": cfg['data']['data_run_id'],\n",
    "        \"vectorizer_max_features\": cfg['vectorizer']['max_features'],\n",
    "        \"vectorizer_ngram_range\": str(cfg['vectorizer']['ngram_range']),\n",
    "        \"vectorizer_max_df\": cfg['vectorizer']['max_df'],\n",
    "        \"vectorizer_min_df\": cfg['vectorizer']['min_df'],\n",
    "        \"lda_max_iter\": cfg['lda']['max_iter']\n",
    "    })\n",
    "    \n",
    "    # LDA\n",
    "    lda = LDA(\n",
    "        n_components=cfg['lda']['n_components'],\n",
    "        max_iter=cfg['lda']['max_iter'],    \n",
    "        learning_method=cfg['lda']['learning_method'],\n",
    "        evaluate_every=cfg['lda']['evaluate_every'],\n",
    "        random_state=cfg['lda']['random_state'],\n",
    "        verbose=1,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    lda.fit(dataset)\n",
    "\n",
    "    # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ç–µ–º—ã\n",
    "    topics = extract_topics(lda, vectorizer, n_words=10)\n",
    "    \n",
    "    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –±–∏–≥—Ä–∞–º–º—ã –¥–ª—è –∫–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç–∏\n",
    "    valid_topics = []\n",
    "    for topic in topics:\n",
    "        words = []\n",
    "        for phrase in topic:\n",
    "            words.extend(str(phrase).split())\n",
    "        # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã\n",
    "        unique_words = list(dict.fromkeys(words))\n",
    "        valid_topics.append(unique_words[:10])\n",
    "    \n",
    "    # –ö–æ–≥–µ—Ä–µ–Ω—Ç–Ω–æ—Å—Ç—å\n",
    "    if len(texts_list) > 2000:\n",
    "        texts_list = texts_list[:2000]\n",
    "    \n",
    "    try:\n",
    "        coherence = calculate_coherence(valid_topics, texts_list)\n",
    "    except:\n",
    "        coherence = 0.0\n",
    "    \n",
    "    # –ú–µ—Ç—Ä–∏–∫–∏\n",
    "    mlflow.log_metrics({\n",
    "        \"perplexity\": lda.perplexity(dataset),\n",
    "        \"coherence\": coherence,\n",
    "        \"log_likelihood\": lda.score(dataset)\n",
    "    })\n",
    "    \n",
    "    # –°–æ—Ö—Ä–∞–Ω—è–µ–º\n",
    "    mlflow.sklearn.log_model(vectorizer, \"vectorizer\")\n",
    "    mlflow.sklearn.log_model(lda, \"lda_model\")\n",
    "    \n",
    "    # –¢–µ–º—ã\n",
    "    topics_text = \"\\n\".join([f\"–¢–µ–º–∞ {i}: {', '.join(words)}\" \n",
    "                           for i, words in enumerate(topics, 1)])\n",
    "    mlflow.log_text(topics_text, \"topics.txt\")\n",
    "    \n",
    "    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "    print(f\"–¢–µ–º—ã: {cfg['lda']['n_components']}\")\n",
    "    print(f\"Perplexity: {lda.perplexity(dataset):.2f}\")\n",
    "    print(f\"Coherence: {coherence:.4f}\")\n",
    "    print(f\"Run ID: {run.info.run_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
